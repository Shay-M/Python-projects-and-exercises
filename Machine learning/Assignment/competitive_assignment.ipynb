{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3 - Competitive Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preceding Step - import modules (packages)\n",
    "Shay Mualem 200332435 <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shay Mualem 200332435"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# imports for reading and writing (input & output) files:\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "import string\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading input files\n",
    "Reading input files for train annotated corpus (raw text data) corpus and for the test corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into two data frames, one for metrics, the other for grouping\n",
    "def load_dataset(file_name, category):\n",
    "    data = pd.read_excel(file_name,  'corpus', index_col=None, na_values=['NA'])\n",
    "    return (data.loc[:, data.columns != category].squeeze() , data[category].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = '.' + os.sep + 'input' + os.sep + 'annotated_corpus_for_train.xlsx'\n",
    "test_filename  = '.' + os.sep + 'input' + os.sep + 'corpus_for_test.xlsx'\n",
    "\n",
    "#load the xlsx files\n",
    "df_test  = pd.read_excel(test_filename,  'corpus', index_col = None, na_values=['NA'])\n",
    "df_train = pd.read_excel(train_filename, 'corpus', index_col = None, na_values=['NA'])\n",
    "\n",
    "#split df using load_dataset fun\n",
    "df_train_story, df_train_gender = load_dataset(train_filename,'gender')\n",
    "\n",
    "#conver to binary, not use to see\n",
    "# df_train_gender = df_train_gender.replace(\"f\", \"1\")\n",
    "# df_train_gender = df_train_gender.replace(\"m\", \"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create manually tokenizer\n",
    "\n",
    "def my_tokenizer(text):\n",
    "    # create a space between special characters\n",
    "    text = re.sub(\"(\\\\W)\",\" \\\\1 \",text)\n",
    "    # split based on whitespace\n",
    "    return re.split(\"\\\\s+\" ,text)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# my FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word thar have 'ani' and  with 'hii' can have 'maod' or 'mmas'\n",
    "\n",
    "def num_of_word_ani_end_hay(text):\n",
    "    text_with_hay = (re.findall(r\"(((אני|הייתי)( )(ממש|מאוד)?( )?[א-ת]+[ה][\\s]))\",text))\n",
    "     #if have make it strong vec and need to be more then 8 letr\n",
    "\n",
    "    return len(text_with_hay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find 'ben-zogy word'\n",
    "\n",
    "def num_of_zogi(text):\n",
    "    text_with_hay = (re.findall(r\"((בן)( )(זוג))\",text))\n",
    "        \n",
    "    return len(text_with_hay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word thar have 'ani' and  with 'taf' can have 'maod' or 'mmas'\n",
    "\n",
    "def num_of_word_ani_end_tof_endmod_mmas(text):\n",
    "    text_with_taf = (re.findall(r\"(((אני|הייתי)( )(ממש|מאוד)?( )?[א-ת]+[ת][\\s]))\",text))\n",
    "    \n",
    "    return len(text_with_taf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word thar and with 'it'\n",
    "\n",
    "def num_of_end_et(text):\n",
    "    \n",
    "    return len(re.findall(\"([א-ת]+(ית)[ ])\", text)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def avg_of_word_len(storys):\n",
    "    \n",
    "#     return (sum(len(word) for word in storys) / len(storys.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def number_of_new_lain(storys):\n",
    "#     return len(re.findall(\"\\n\", storys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def num_of_numbers(text):\n",
    "#     print(len(re.findall(\"\\d+\", text)))\n",
    "#     return len(re.findall(\"\\d+\", text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #word thar and with 'vit'\n",
    "\n",
    "# def num_of_end_v_et(text):\n",
    "    \n",
    "#     return len(re.findall(\"([א-ת]+(ות)[ ])\", text)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using Pipeline: TfidfVectorizer > FunctionTransformer > SGDClassifier\n",
    "# i got this number min_df = 3 , max_df = 0.9 by using alot of trying\n",
    "    \n",
    "classifier = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('text', Pipeline([\n",
    "            ('vectorizer', TfidfVectorizer(min_df = 3 , max_df = 0.9 ,tokenizer = my_tokenizer)),\n",
    "#             ('tfidf', TfidfTransformer()),\n",
    "        ])),\n",
    "        \n",
    "#      ('try', Pipeline([\n",
    "         ('ani_end_tof', FunctionTransformer(lambda x: np.array([num_of_word_ani_end_tof_endmod_mmas(t) for t in x]).reshape(-1, 1), validate=False)),\n",
    "         ('num_of_bnZogi', FunctionTransformer(lambda x: np.array([num_of_zogi(t) for t in x]).reshape(-1, 1), validate=False)),\n",
    "         ('num_of_word_ani_end_hay', FunctionTransformer(lambda x: np.array([num_of_word_ani_end_hay(t) for t in x]).reshape(-1, 1), validate=False)),\n",
    "         ('new_lain', FunctionTransformer(lambda x: np.array([num_of_end_et(t) for t in x]).reshape(-1, 1), validate=False)),\n",
    "#          ('num_of_numbers', FunctionTransformer(lambda x: np.array([num_of_end_v_et(t) for t in x]).reshape(-1, 1), validate=False)),\n",
    "#          ('num_of_end_et', FunctionTransformer(lambda x: np.array([avg_of_word_len(t) for t in x]).reshape(-1, 1), validate=False)),\n",
    "#          ]))\n",
    "    ])),\n",
    "    ('clf-svm', SGDClassifier(loss='hinge', penalty='l2' ,alpha=1e-3, tol=None))])\n",
    "\n",
    "classifier =  classifier.fit(df_train_story, df_train_gender)\n",
    "\n",
    "# classifier.named_steps[\"features\"].get_feature_names()\n",
    "# # pd.DataFrame(classifier.named_steps[\"vect\"].get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing cross-validated metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.8844919786096257\n",
      "mean/avg:  0.8009793727730316\n",
      "min:  0.6210526315789474\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "df_train, Y1 = load_dataset(train_filename,'gender')\n",
    "\n",
    "#using  cross val with 6 fold cross validation using f1\n",
    "scores = cross_val_score(classifier, df_train,Y1 , cv = 10, scoring = 'f1_macro')\n",
    "\n",
    "print('max: ', scores.max())\n",
    "print('mean/avg: ', scores.mean()) # < what we need\n",
    "print('min: ', scores.min())\n",
    "\n",
    "# max:  0.8937799043062201\n",
    "# mean/avg:  0.8050399028861932\n",
    "# min:  0.6210526315789474"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your implementation:\n",
    "Write your code solution in the following code-cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    כחלק ממסגרת ההתנדבות שלי במגלה אני הולך לפעמיי...\n",
       "1    לפני שנה החלטתי שאני רוצה להיות טייס, התחלתי ל...\n",
       "2    בתקופת הקורונה של תחילת החיסונים נגד קורונה, א...\n",
       "3    כפי שכולם מכירים או שמעו מחברים עולם הדייטים ה...\n",
       "4    אחת החוויות שהכי זכורות לי, זו החוויה בפרו בטי...\n",
       "Name: story, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The stories from the test\n",
    "df_test['story'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['m', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm',\n",
       "       'm', 'm', 'f', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm',\n",
       "       'm', 'f', 'm', 'm', 'm', 'f', 'm', 'f', 'm', 'm', 'm', 'f', 'm',\n",
       "       'f', 'm', 'm', 'm', 'm', 'm', 'm', 'f', 'm', 'm', 'm', 'f', 'f',\n",
       "       'm', 'm', 'm', 'f', 'f', 'f', 'm', 'm', 'm', 'm', 'm', 'm', 'f',\n",
       "       'f', 'm', 'f', 'f', 'm', 'm', 'f', 'm', 'm', 'm', 'm', 'm', 'm',\n",
       "       'm', 'm', 'f', 'm', 'm', 'm', 'm', 'f', 'm', 'm', 'm', 'm', 'm',\n",
       "       'm', 'f', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm',\n",
       "       'm', 'f', 'm', 'm', 'm', 'm', 'f', 'm', 'm', 'm', 'm', 'm', 'm',\n",
       "       'm', 'f', 'm', 'm', 'f', 'm', 'f', 'm', 'f', 'm', 'm', 'm', 'm',\n",
       "       'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'f',\n",
       "       'm', 'm', 'm', 'f', 'f', 'm', 'f', 'm', 'm', 'm', 'm', 'm', 'f'],\n",
       "      dtype='<U1')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is my predicten\n",
    "my_test_predicted = classifier.predict(df_test['story'])\n",
    "my_test_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_predicted = pd.DataFrame(df_test['test_example_id'], ndarray_predicted, columns = ['test_example_id','predicted_category'])\n",
    "df_predicted = pd.DataFrame([df_test['test_example_id'] , my_test_predicted]).T\n",
    "df_predicted.columns=['test_example_id','predicted_category']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_example_id</th>\n",
       "      <th>predicted_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>151</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>152</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>153</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>154</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>155</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    test_example_id predicted_category\n",
       "0                 0                  m\n",
       "1                 1                  m\n",
       "2                 2                  m\n",
       "3                 3                  m\n",
       "4                 4                  m\n",
       "..              ...                ...\n",
       "151             151                  m\n",
       "152             152                  m\n",
       "153             153                  m\n",
       "154             154                  m\n",
       "155             155                  f\n",
       "\n",
       "[156 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the df_predicted id and predicted_category\n",
    "df_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save output to csv\n",
    "After you're done save your output to the 'classification_results.csv' csv file.<br/>\n",
    "We assume that the dataframe with your results contain the following columns:\n",
    "* column 1 (left column): 'test_example_id'  - the same id associated to each of the test stories to be predicted.\n",
    "* column 2 (right column): 'predicted_category' - the predicted gender value for each of the associated story. \n",
    "\n",
    "Assuming your predicted values are in the `df_predicted` dataframe, you should save you're results as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted.to_csv('classification_results.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
