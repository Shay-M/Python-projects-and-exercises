{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credits: This notebook contains an excerpt from the [Python Data Science Handbook]\n",
    "by Jake VanderPlas;\n",
    "\n",
    "*The text is released under the [CC-BY-NC-ND license](https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode), and code is released under the [MIT license](https://opensource.org/licenses/MIT). <br/>\n",
    "If you find this content useful, please consider supporting the work by [buying the book](http://shop.oreilly.com/product/0636920034919.do)!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our previous lessons and assignment the examples we assume that <br/>\n",
    "    you have a examples in a dataset format.\n",
    "    \n",
    "In the real world, data rarely comes in such a form.\n",
    "\n",
    "In this notebook we will practice vectorization of text data (and some categorical data).\n",
    "\n",
    "In this notebook, we will review the following:<br/>\n",
    "* The CountVectorizer\n",
    "* The TfidfVectorizer\n",
    "* The DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T17:08:25.236720Z",
     "start_time": "2021-05-05T17:08:23.023659Z"
    }
   },
   "outputs": [],
   "source": [
    "# Standard Improts\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "# show several prints in one cell. This will allow us to condence every trick in one cell.\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Features\n",
    "In the vectorization process of text features we need to convert text to a set of representative numerical values.<br/>\n",
    "For example, most automatic mining of social media data relies on some form of encoding the text as numbers.<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The CountVectorizer\n",
    "One of the simplest methods of encoding data is by *word counts*: <br/>\n",
    "you take each snippet of text, count the occurrences of each word within it, <br/>\n",
    "and put the results in a table.\n",
    "\n",
    "For example, consider the following set of three phrases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T17:13:51.344876Z",
     "start_time": "2021-05-05T17:13:51.333878Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = ['problem of evil',\n",
    "          'evil queen is evil',\n",
    "          'horizon problem']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a vectorization of this data based on word count, we could construct <br/>\n",
    "   a column representing the word \"problem,\" the word \"evil,\" the word \"horizon,\" and so on.<br/>\n",
    "   \n",
    "While doing this by hand would be possible, the tedium can be avoided by using Scikit-Learn's ``CountVectorizer``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T17:13:55.195538Z",
     "start_time": "2021-05-05T17:13:55.177538Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['problem of evil', 'evil queen is evil', 'horizon problem']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<3x6 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 8 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 1, 1, 0],\n",
       "       [2, 0, 1, 0, 0, 1],\n",
       "       [0, 1, 0, 0, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "sample\n",
    "vec = CountVectorizer()\n",
    "X_train = vec.fit_transform(sample)\n",
    "type(X_train)\n",
    "X_train\n",
    "type(X_train.toarray())\n",
    "X_train.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a sparse matrix recording the number of times each word appears; it is easier to inspect if we convert this to a ``DataFrame`` with labeled columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T17:14:38.120921Z",
     "start_time": "2021-05-05T17:14:38.093927Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['problem of evil', 'evil queen is evil', 'horizon problem']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evil</th>\n",
       "      <th>horizon</th>\n",
       "      <th>is</th>\n",
       "      <th>of</th>\n",
       "      <th>problem</th>\n",
       "      <th>queen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   evil  horizon  is  of  problem  queen\n",
       "0     1        0   0   1        1      0\n",
       "1     2        0   1   0        0      1\n",
       "2     0        1   0   0        1      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sample\n",
    "pd.DataFrame(X_train.toarray(), columns=vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T17:15:35.300335Z",
     "start_time": "2021-05-05T17:15:35.264333Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['big problem problem', 'not evil queen', 'the horizon']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evil</th>\n",
       "      <th>horizon</th>\n",
       "      <th>is</th>\n",
       "      <th>of</th>\n",
       "      <th>problem</th>\n",
       "      <th>queen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   evil  horizon  is  of  problem  queen\n",
       "0     0        0   0   0        2      0\n",
       "1     1        0   0   0        0      1\n",
       "2     0        1   0   0        0      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test = ['big problem problem',\n",
    "          'not evil queen',\n",
    "          'the horizon']\n",
    "sample_test\n",
    "X_test= vec.transform(sample_test)\n",
    "pd.DataFrame(X_test.toarray(), columns=vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some parameters you should review:\n",
    "* **analyzer** - default=’word’ but we could change to ‘char’, ‘char_wb’\n",
    "  * Option ‘char_wb’ creates character n-grams only from text inside word boundaries\n",
    "* **tokenizer** - Override the string tokenization step while preserving the preprocessing and n-grams generation steps\n",
    "* **stop_words** - if a list is set (stop_words=python_lst), it is assumed to contain stop words, all of which will be removed from the resulting tokens.\n",
    "* **ngram_range** - tuple - (min_n, max_n), default=(1, 1) - if changed we could catch ngrams.\n",
    "* **min_df** - float in range [0.0, 1.0] or int, default=1 - the minimum number of documents (or ratio of documents), for which the word (or basic unit) should appear in.\n",
    "* **max_df** - float in range [0.0, 1.0] or int, default=1.0 - the maximum number of documents (or ratio of documents), for which the word (or basic unit) should appear in.\n",
    "* **max_features** - int, default=None - max_features ordered by term frequency across the corpus.\n",
    "* **vocabulary** - Mapping or iterable, default=None - mapping functions as a dictionary (e.g., a list similar words as values), or a close-list of words, which only these words will be considered in the language \n",
    "* **dtype** - type, default=np.int64 -  the type of the value of the feature\n",
    "\n",
    "For additional information click the link: [sklearn's CountVectorizer documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T17:18:51.294299Z",
     "start_time": "2021-05-05T17:18:51.252301Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['problem of evil', 'evil queen is evil', 'horizon problem']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<3x12 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 14 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0],\n",
       "       [2, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evil</th>\n",
       "      <th>evil queen</th>\n",
       "      <th>horizon</th>\n",
       "      <th>horizon problem</th>\n",
       "      <th>is</th>\n",
       "      <th>is evil</th>\n",
       "      <th>of</th>\n",
       "      <th>of evil</th>\n",
       "      <th>problem</th>\n",
       "      <th>problem of</th>\n",
       "      <th>queen</th>\n",
       "      <th>queen is</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   evil  evil queen  horizon  horizon problem  is  is evil  of  of evil  \\\n",
       "0     1           0        0                0   0        0   1        1   \n",
       "1     2           1        0                0   1        1   0        0   \n",
       "2     0           0        1                1   0        0   0        0   \n",
       "\n",
       "   problem  problem of  queen  queen is  \n",
       "0        1           1      0         0  \n",
       "1        0           0      1         1  \n",
       "2        1           0      0         0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "sample\n",
    "vec_ngrams = CountVectorizer(ngram_range=(1,2))\n",
    "X_train = vec_ngrams.fit_transform(sample)\n",
    "type(X_train)\n",
    "X_train\n",
    "type(X_train.toarray())\n",
    "X_train.toarray()\n",
    "pd.DataFrame(X_train.toarray(), columns=vec_ngrams.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The TfidfVectorizer\n",
    "There are some issues with the `CountVectorizer` approach, <br/>\n",
    "   the raw word counts lead to features which put too much weight on words that appear very frequently, <br/>\n",
    "   and this can be sub-optimal in some classification algorithms.<br/>\n",
    "\n",
    "One approach to fix this is known as *term frequency-inverse document frequency* (*TF–IDF*),<br/>\n",
    "   which weights the word counts by a measure of how often they appear in the documents.<br/>\n",
    "The syntax for computing these features is similar to the previous example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T17:21:51.429090Z",
     "start_time": "2021-05-05T17:21:51.412087Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['problem of evil', 'evil queen is evil', 'horizon problem']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evil</th>\n",
       "      <th>horizon</th>\n",
       "      <th>is</th>\n",
       "      <th>of</th>\n",
       "      <th>problem</th>\n",
       "      <th>queen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.517856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.680919</td>\n",
       "      <td>0.517856</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.732359</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.481482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.481482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.795961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.605349</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       evil   horizon        is        of   problem     queen\n",
       "0  0.517856  0.000000  0.000000  0.680919  0.517856  0.000000\n",
       "1  0.732359  0.000000  0.481482  0.000000  0.000000  0.481482\n",
       "2  0.000000  0.795961  0.000000  0.000000  0.605349  0.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vec = TfidfVectorizer()\n",
    "X = vec.fit_transform(sample)\n",
    "sample\n",
    "pd.DataFrame(X.toarray(), columns=vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some parameters you should review:\n",
    "* **norm** -  default=’l2’ - ‘l1’ also possible. \n",
    "  * `'l2'` - sum of squares of vector elements is 1,\n",
    "  * `'l1'` - Sum of absolute values of vector elements is 1\n",
    "* **use_idf** - bool, default=True - if is False, like CountVectorizer, but with tf, instead of count.\n",
    "* **sublinear_tf** - bool, default=False - if is True (zipf law), replace tf with 1 + log(tf).\n",
    "\n",
    "* **stop_words** - if a list is set (stop_words=python_lst), it is assumed to contain stop words, all of which will be removed from the resulting tokens.\n",
    "* **ngram_range** - tuple - (min_n, max_n), default=(1, 1) - if changed we could catch ngrams.\n",
    "* **min_df** - float in range [0.0, 1.0] or int, default=1 - the minimum number of documents (or ratio of documents), for which the word (or basic unit) should appear in.\n",
    "* **max_df** - float in range [0.0, 1.0] or int, default=1.0 - the maximum number of documents (or ratio of documents), for which the word (or basic unit) should appear in.\n",
    "* **max_features** - int, default=None - max_features ordered by term frequency across the corpus.\n",
    "* **vocabulary** - Mapping or iterable, default=None - mapping functions as a dictionary (e.g., a list similar words as values), or a close-list of words, which only these words will be considered in the language \n",
    "* **dtype** - type, default=np.int64 -  the type of the value of the feature\n",
    "\n",
    "For additional information click the link: [sklearn's TfidfVectorizer documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The DictVectorizer\n",
    "\n",
    "One common type of non-numerical data is *categorical* data. <br/>\n",
    "For example, imagine you are exploring some data on housing prices, <br/>\n",
    "and along with numerical features like \"price\" and \"rooms\", you also have \"neighborhood\" information.<br/>\n",
    "\n",
    "For example, your data might look something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T17:27:43.566489Z",
     "start_time": "2021-05-05T17:27:43.558491Z"
    }
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    {'price': 850000, 'rooms': 4, 'neighborhood': 'Queen Anne'},\n",
    "    {'price': 700000, 'rooms': 3, 'neighborhood': 'Fremont'},\n",
    "    {'price': 650000, 'rooms': 3, 'neighborhood': 'Wallingford'},\n",
    "    {'price': 600000, 'rooms': 2, 'neighborhood': 'Fremont'}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might be tempted to encode this data with a straightforward numerical mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T17:27:57.981232Z",
     "start_time": "2021-05-05T17:27:57.974263Z"
    }
   },
   "outputs": [],
   "source": [
    "# Is this a good solution?\n",
    "{'Queen Anne': 1, 'Fremont': 2, 'Wallingford': 3};"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus such a mapping would imply, for example, that *Queen Anne < Fremont < Wallingford*, or even that *Wallingford - Queen Anne = Fremont*, which (niche demographic jokes aside) does not make much sense.\n",
    "\n",
    "In this case, one proven technique is to use *one-hot encoding*, <br/>\n",
    "which effectively creates extra columns indicating the presence or absence of a category with a value of 1 or 0, respectively.<br/>\n",
    "It is also useful for user processed text, as well as predefined dictionaries (e.g., of city names).\n",
    "\n",
    "When your data comes as a list of dictionaries, Scikit-Learn's ``DictVectorizer`` will do this for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T17:31:26.557710Z",
     "start_time": "2021-05-05T17:31:26.539713Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'price': 850000, 'rooms': 4, 'neighborhood': 'Queen Anne'},\n",
       " {'price': 700000, 'rooms': 3, 'neighborhood': 'Fremont'},\n",
       " {'price': 650000, 'rooms': 3, 'neighborhood': 'Wallingford'},\n",
       " {'price': 600000, 'rooms': 2, 'neighborhood': 'Fremont'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighborhood=Fremont</th>\n",
       "      <th>neighborhood=Queen Anne</th>\n",
       "      <th>neighborhood=Wallingford</th>\n",
       "      <th>price</th>\n",
       "      <th>rooms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>850000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>700000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>650000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>600000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   neighborhood=Fremont  neighborhood=Queen Anne  neighborhood=Wallingford  \\\n",
       "0                     0                        1                         0   \n",
       "1                     1                        0                         0   \n",
       "2                     0                        0                         1   \n",
       "3                     1                        0                         0   \n",
       "\n",
       "    price  rooms  \n",
       "0  850000      4  \n",
       "1  700000      3  \n",
       "2  650000      3  \n",
       "3  600000      2  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "vec_dict = DictVectorizer(sparse=False, dtype=int)\n",
    "train_vector = vec_dict.fit_transform(data)\n",
    "data\n",
    "pd.DataFrame(train_vector, columns=vec_dict.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice that the 'neighborhood' column has been expanded into three separate columns**, <br/>\n",
    "representing the three neighborhood labels, <br/>\n",
    "and that each row has a 1 in the column associated with its neighborhood.<br/>\n",
    "With these categorical features thus encoded, you can proceed as normal with fitting a Scikit-Learn model.\n",
    "\n",
    "To see the meaning of each column, you can inspect the feature names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T14:54:33.012523Z",
     "start_time": "2021-05-05T14:54:33.002515Z"
    }
   },
   "outputs": [],
   "source": [
    "vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DictVectorizer - the sparse=True option\n",
    "There is one clear disadvantage of this approach: <br/>\n",
    "if your category has many possible values, this can *greatly* increase the size of your dataset.\n",
    "However, because the encoded data contains mostly zeros, a sparse output can be a very efficient solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T17:33:41.003929Z",
     "start_time": "2021-05-05T17:33:40.982928Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<4x5 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 12 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[     0,      1,      0, 850000,      4],\n",
       "       [     1,      0,      0, 700000,      3],\n",
       "       [     0,      0,      1, 650000,      3],\n",
       "       [     1,      0,      0, 600000,      2]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = DictVectorizer(sparse=True, dtype=int)\n",
    "sparse_vector = vec.fit_transform(data)\n",
    "type(sparse_vector)\n",
    "sparse_vector\n",
    "sparse_vector.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many (though not yet all) of the Scikit-Learn estimators accept such sparse inputs when fitting and evaluating models. ``sklearn.preprocessing.OneHotEncoder`` and ``sklearn.feature_extraction.FeatureHasher`` are two additional tools that Scikit-Learn includes to support this type of encoding.\n",
    "\n",
    "For additional information click the link: [sklearn's DictVectorizer documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
